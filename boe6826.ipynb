{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network for resolution enhancement and noise reduction in acoustic resolution photoacoustic microscopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在声学分辨率光声显微镜（AR-PAM）中，高数值孔径聚焦超声换能器（UST）用于深部组织高分辨率光声成像。 离焦区域的横向分辨率明显降低。\n",
    "# 在不降低图像质量的情况下提高离焦分辨率仍然是一个挑战。 在这项工作中，我们提出了一种基于深度学习的方法来提高AR-PAM图像的分辨率，\n",
    "# 尤其是在焦平面外的情况下。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构和FDUnet很像，几乎一样\n",
    "（1）在网络的开始和结尾处增加层数，输入大小为256×256，从而有助于将像素大小保持为小于系统分辨率； \n",
    "（2）在3x3卷积里加了dropout层，防止过拟合；\n",
    "（3）最后的输出处加了一个relu，促进残差学习，即网络学习了R，其中ReLU（R + X）=Y。网络学习R而不是Y更容易，可以更快地训练网络[39]。 \n",
    "\n",
    "#  数据集仿真 by simulating B-scans using k-wave toolbox in MATLAB \n",
    "# 输入图片40kb左右，输出只有0字节，大小都是278*278\n",
    "# 输入shuc他们的大致位置是一样的，可以理解为是分辨率增强；真值是一个球的地方，对应输入处是一个弧线scan？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1测试集；剩余8:2分配  training (1508), validation (377), and testing (210)  SNR was 10 dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from os import makedirs\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "########################################################################################################################\n",
    "'''initialize constants'''\n",
    "########################################################################################################################\n",
    "seed = 7\n",
    "np.random.seed = seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1\n",
    "########################################################################################################################\n",
    "'''Load dataset'''\n",
    "########################################################################################################################\n",
    "TRAIN_PATH = 'Simulated_dataset/'\n",
    "data_ids = [filename for filename in os.listdir(TRAIN_PATH) if filename.startswith(\"x_\")]\n",
    "\n",
    "NUMBER_OF_SAMPLES = int(len(data_ids))\n",
    "print(NUMBER_OF_SAMPLES)\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "'''Folder for saving the model'''\n",
    "########################################################################################################################\n",
    "MODEL_NAME = 'modelFDUNET.h5'\n",
    "\n",
    "X_total = np.zeros((NUMBER_OF_SAMPLES, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_total = np.zeros((NUMBER_OF_SAMPLES, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "NUMBER_EPOCHS = 250\n",
    "PATIENCE = 10\n",
    "MONITOR = 'val_loss'\n",
    "\n",
    "im = TRAIN_PATH.split(\"d\", 1)[1]\n",
    "FOLDER_NAME = \"modelARPAM\"\n",
    "makedirs(FOLDER_NAME)\n",
    "MODEL_NAME = FOLDER_NAME + MODEL_NAME\n",
    "LOG_NAME = FOLDER_NAME + \"logs\"\n",
    "\n",
    "########################################################################################################################\n",
    "'''Image augmentation'''\n",
    "########################################################################################################################\n",
    "print('Resizing training images and masks')\n",
    "for data, val in enumerate(data_ids):\n",
    "    ext = val.split(\"_\", 1)[1] #To get the number after x_\n",
    "    xpath = TRAIN_PATH + val\n",
    "    ypath = TRAIN_PATH + 'y_' + ext\n",
    "\n",
    "    img = imread(xpath)#[:, :, :IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    img = np.expand_dims(img, axis=2)\n",
    "    X_total[data] = img  # Fill empty X_train with values from img\n",
    "\n",
    "    true_img = imread(ypath)#[:, :, :IMG_CHANNELS]\n",
    "    true_img = resize(true_img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    true_img = np.expand_dims(true_img, axis=2)\n",
    "    Y_total[data] = true_img\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "'''Divide in training and test data'''\n",
    "########################################################################################################################\n",
    "test_split = 0.1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_total, Y_total, test_size=test_split, random_state=seed)\n",
    "\n",
    "Y_pred = np.zeros((len(X_test), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=seed)\n",
    "\n",
    "print('Done splitting and shuffling')\n",
    "\n",
    "########################################################################################################################\n",
    "'''Network functions'''\n",
    "########################################################################################################################\n",
    "def Conv2D_BatchNorm(input, filters, kernel_size, strides, activation, kernel_initializer, padding):\n",
    "    out = tf.keras.layers.Conv2D(filters, kernel_size=kernel_size, strides= strides, activation=activation, kernel_initializer=kernel_initializer, padding=padding)(input)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "                                            beta_initializer='zeros', gamma_initializer='ones',\n",
    "                                            moving_mean_initializer='zeros',\n",
    "                                            moving_variance_initializer='ones', beta_regularizer=None,\n",
    "                                            gamma_regularizer=None,\n",
    "                                            beta_constraint=None, gamma_constraint=None)(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def Conv2D_Transpose_BatchNorm(input, filters, kernel_size, strides, activation, kernel_initializer, padding):\n",
    "    out = tf.keras.layers.Conv2DTranspose(filters, kernel_size=kernel_size, strides= strides, activation=activation, kernel_initializer=kernel_initializer, padding=padding)(input)\n",
    "    out = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "                                            beta_initializer='zeros', gamma_initializer='ones',\n",
    "                                            moving_mean_initializer='zeros',\n",
    "                                            moving_variance_initializer='ones', beta_regularizer=None,\n",
    "                                            gamma_regularizer=None,\n",
    "                                            beta_constraint=None, gamma_constraint=None)(out)\n",
    "    return out\n",
    "\n",
    "def DownBlock(input, filters, kernel_size, padding, activation, kernel_initializer):\n",
    "    out = FD_Block(input, f_in=filters // 2, f_out=filters, k=filters // 8, kernel_size=3, padding='same',\n",
    "                   activation=activation, kernel_initializer='glorot_normal')\n",
    "    shortcut = out\n",
    "    out = DownSample(out, filters, kernel_size, strides=2, padding=padding,\n",
    "                     activation=activation, kernel_initializer=kernel_initializer)\n",
    "    return [out, shortcut]\n",
    "\n",
    "\n",
    "def BrigdeBlock(input, filters, kernel_size, padding, activation, kernel_initializer):\n",
    "    out = FD_Block(input, f_in=filters // 2, f_out=filters, k=filters // 8, kernel_size=3, padding='same',\n",
    "                   activation=activation, kernel_initializer='glorot_normal')\n",
    "    out = UpSample(out, filters, kernel_size, strides=2, padding=padding,\n",
    "                   activation=activation, kernel_initializer=kernel_initializer)\n",
    "    return out\n",
    "\n",
    "\n",
    "def UpBlock(input, filters, kernel_size, padding, activation, kernel_initializer):\n",
    "    out = Conv2D_BatchNorm(input, filters= filters//2, kernel_size=1, strides=1, activation=activation,\n",
    "                           kernel_initializer=kernel_initializer, padding=padding)\n",
    "    out = FD_Block(out, f_in=filters // 2, f_out=filters, k=filters // 8, kernel_size=3, padding='same',\n",
    "                   activation=activation, kernel_initializer='glorot_normal')\n",
    "    out = UpSample(out, filters, kernel_size, strides=2, padding=padding,\n",
    "                     activation=activation, kernel_initializer=kernel_initializer)\n",
    "    return out\n",
    "\n",
    "\n",
    "def FD_Block(input, f_in, f_out, k, kernel_size, padding, activation, kernel_initializer):\n",
    "    out = input\n",
    "    for i in range(f_in, f_out, k):\n",
    "        shortcut = out\n",
    "        out = Conv2D_BatchNorm(out, filters=f_in, kernel_size=1, strides=1, padding=padding,\n",
    "                               activation=activation, kernel_initializer=kernel_initializer)\n",
    "        out = Conv2D_BatchNorm(out, filters=k, kernel_size=kernel_size, strides=1, padding=padding,\n",
    "                               activation=activation, kernel_initializer=kernel_initializer)\n",
    "        out = tf.keras.layers.Dropout(0.7, seed=seed)(out)\n",
    "        out = tf.keras.layers.concatenate([out, shortcut])\n",
    "    return out\n",
    "\n",
    "\n",
    "def DownSample(input, filters, kernel_size, strides, padding, activation, kernel_initializer):\n",
    "    out = Conv2D_BatchNorm(input, filters, kernel_size=1, strides=1, activation= activation, kernel_initializer= kernel_initializer, padding=padding)\n",
    "    out = Conv2D_BatchNorm(out, filters, kernel_size=kernel_size, strides=strides, activation=activation,\n",
    "                           kernel_initializer=kernel_initializer, padding=padding)\n",
    "    return out\n",
    "\n",
    "def UpSample(input, filters, kernel_size, strides, padding, activation, kernel_initializer):\n",
    "    out = Conv2D_BatchNorm(input, filters, kernel_size=1, strides=1, padding=padding,\n",
    "                           activation=activation, kernel_initializer=kernel_initializer)\n",
    "    out = Conv2D_Transpose_BatchNorm(out, filters//2, kernel_size=kernel_size, strides=strides, activation=activation,\n",
    "                           kernel_initializer=kernel_initializer, padding=padding)\n",
    "    return out\n",
    "\n",
    "\n",
    "########################################################################################################################\n",
    "'''Define parameters'''\n",
    "########################################################################################################################\n",
    "kernel_initializer = tf.keras.initializers.glorot_normal(seed=seed)\n",
    "activation = 'relu'\n",
    "filters = 16\n",
    "padding = 'same'\n",
    "kernel_size = 3\n",
    "strides = 1\n",
    "\n",
    "inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = inputs\n",
    "\n",
    "out = Conv2D_BatchNorm(s, filters, kernel_size=kernel_size, strides= strides, activation=activation, kernel_initializer=kernel_initializer, padding=padding)\n",
    "\n",
    "[out, c1] = DownBlock(out, filters*2**1, kernel_size, padding, activation, kernel_initializer)\n",
    "[out, c2] = DownBlock(out, filters*2**2, kernel_size, padding, activation, kernel_initializer)\n",
    "[out, c3] = DownBlock(out, filters*2**3, kernel_size, padding, activation, kernel_initializer)\n",
    "[out, c4] = DownBlock(out, filters*2**4, kernel_size, padding, activation, kernel_initializer)\n",
    "[out, c5] = DownBlock(out, filters*2**5, kernel_size, padding, activation, kernel_initializer)\n",
    "\n",
    "out = BrigdeBlock(out, filters*2**6, kernel_size, padding, activation, kernel_initializer)\n",
    "\n",
    "out = tf.keras.layers.concatenate([out, c5])\n",
    "out = UpBlock(out, filters*2**5, kernel_size, padding, activation, kernel_initializer)\n",
    "\n",
    "\n",
    "out = tf.keras.layers.concatenate([out, c4])\n",
    "out = UpBlock(out, filters*2**4, kernel_size, padding, activation, kernel_initializer)\n",
    "out = tf.keras.layers.concatenate([out, c3])\n",
    "out = UpBlock(out, filters*2**3, kernel_size, padding, activation, kernel_initializer)\n",
    "out = tf.keras.layers.concatenate([out, c2])\n",
    "out = UpBlock(out, filters*2**2, kernel_size, padding, activation, kernel_initializer)\n",
    "out = tf.keras.layers.concatenate([out, c1])\n",
    "\n",
    "out = Conv2D_BatchNorm(out, filters, kernel_size=1, strides=1, activation=activation, kernel_initializer=kernel_initializer, padding=padding)\n",
    "out = FD_Block(out, f_in=filters, f_out=filters*2, k=filters // 4, kernel_size=3, padding=padding,\n",
    "                   activation=activation, kernel_initializer=kernel_initializer)\n",
    "\n",
    "out = tf.keras.layers.Conv2D(filters=1, kernel_size=1, strides=1, padding=padding, activation='linear', kernel_initializer=kernel_initializer)(out)\n",
    "out = tf.keras.layers.Add()([out, s])\n",
    "out = tf.keras.layers.ReLU()(out)\n",
    "outputs = out\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "########################################################################################################################\n",
    "'''define adam'''\n",
    "########################################################################################################################\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=[tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "########################################################################################################################\n",
    "'''Model checkpoints'''\n",
    "########################################################################################################################\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(MODEL_NAME, verbose=1, save_best_only=True),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=LOG_NAME), \n",
    "\t\ttf.keras.callbacks.EarlyStopping(patience=PATIENCE, monitor=MONITOR)]\n",
    "\n",
    "########################################################################################################################\n",
    "'''Compile model'''\n",
    "########################################################################################################################\n",
    "results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=8, epochs=NUMBER_EPOCHS, callbacks=callbacks)\n",
    "print('Model Trained')\n",
    "\n",
    "########################################################################################################################\n",
    "'''Model evaluvation'''\n",
    "########################################################################################################################\n",
    "model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Done evaluation')\n",
    "preds_test = np.zeros((142, IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.uint8)\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0] * 0.8)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0] * 0.8):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "print('Done prediction on simulation')\n",
    "preds_test_int = preds_test.astype(np.uint8)\n",
    "preds_test_t = tf.convert_to_tensor(preds_test_int)\n",
    "Y_test_t = tf.convert_to_tensor(Y_test)\n",
    "X_test_t = tf.convert_to_tensor(X_test)\n",
    "ssim_test = tf.image.ssim(Y_test_t, preds_test_t, max_val=255)\n",
    "ssim_test_orig = tf.image.ssim(Y_test_t, X_test_t, max_val=255)\n",
    "psnr_test = tf.image.psnr(Y_test_t, preds_test_t, max_val=255)\n",
    "psnr_test_orig = tf.image.psnr(Y_test_t, X_test_t, max_val=255)\n",
    "\n",
    "print('SSIM Test')\n",
    "print(np.mean(ssim_test.numpy()))\n",
    "\n",
    "print('PSNR Test')\n",
    "print(np.mean(psnr_test.numpy()))\n",
    "\n",
    "print('SSIM original')\n",
    "print(np.mean(ssim_test_orig.numpy()))\n",
    "\n",
    "print('PSNR original')\n",
    "print(np.mean(psnr_test_orig.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
