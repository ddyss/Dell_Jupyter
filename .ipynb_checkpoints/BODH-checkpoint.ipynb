{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128, 128])\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7d5be48ae21d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# from torchsummary import summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# summary(djgnet,(1,512,128),1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorwatch\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;31m# model=djgnet()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[0mtw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdjgnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorwatch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#from .receptive_field.rf_utils import plot_receptive_field, plot_grads_at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsne_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_tsne_components\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmodel_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtorchstat_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel_stats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModelStats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg2pyt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinear_to_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyt_ds2list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_by_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol2array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_similar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorwatch\\model_graph\\torchstat_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Licensed under the MIT license.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtorchstat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorwatch\\model_graph\\torchstat\\analyzer.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcompute_memory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompute_memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstat_tree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStatTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStatNode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mreporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreport_format\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mModuleStats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python\\lib\\site-packages\\tensorwatch\\model_graph\\torchstat\\reporter.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "class AsymUNet(nn.Module):\n",
    "    def __init__(self, num_input_channels, base_n_features=32):  # 16 #24ist auch gut):\n",
    "        super(AsymUNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_input_channels, base_n_features, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(base_n_features)\n",
    "        self.conv2 = nn.Conv2d(base_n_features, base_n_features, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(base_n_features)\n",
    "        self.down1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(base_n_features, base_n_features * 2, 3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(base_n_features * 2)\n",
    "        self.conv4 = nn.Conv2d(base_n_features * 2, base_n_features * 2, 3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(base_n_features * 2)\n",
    "        self.down2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(base_n_features * 2, base_n_features * 4, 3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(base_n_features * 4)\n",
    "        self.conv6 = nn.Conv2d(base_n_features * 4, base_n_features * 4, 3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(base_n_features * 4)\n",
    "        self.down3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(base_n_features * 4, base_n_features * 8, 3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(base_n_features * 8)\n",
    "        self.conv8 = nn.Conv2d(base_n_features * 8, base_n_features * 8, 3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(base_n_features * 8)\n",
    "\n",
    "        self.up1 = nn.Upsample(scale_factor=2)\n",
    "        self.conv9 = nn.Conv2d(base_n_features * 8 + base_n_features * 4, base_n_features * 4, 3, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(base_n_features * 4)\n",
    "        self.conv10 = nn.Conv2d(base_n_features * 4, base_n_features * 4, 3, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(base_n_features * 4)\n",
    "\n",
    "        self.up2 = nn.Upsample(scale_factor=2)\n",
    "        self.conv11 = nn.Conv2d(base_n_features * 4 + base_n_features * 2, base_n_features * 2, 3, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(base_n_features * 2)\n",
    "        self.conv12 = nn.Conv2d(base_n_features * 2, base_n_features * 2, 3, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(base_n_features * 2)\n",
    "\n",
    "        self.up3 = nn.Upsample(scale_factor=2)\n",
    "        self.conv13 = nn.Conv2d(base_n_features * 2 + base_n_features, base_n_features, 3, padding=1)\n",
    "        self.bn13 = nn.BatchNorm2d(base_n_features)\n",
    "        self.conv14 = nn.Conv2d(base_n_features * 1, 1, 3, padding=1)\n",
    "\n",
    "        # Skip connnections:\n",
    "        self.skip1 = nn.Conv2d(base_n_features, base_n_features, (6, 3), (4, 1), (1, 1))\n",
    "        self.skip2 = nn.Conv2d(base_n_features * 2, base_n_features * 2, (6, 3), (4, 1), (1, 1))\n",
    "        self.skip3 = nn.Conv2d(base_n_features * 4, base_n_features * 4, (6, 3), (4, 1), (1, 1))\n",
    "        self.skip4 = nn.Conv2d(base_n_features * 8, base_n_features * 8, (6, 3), (4, 1), (1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        s1 = x = F.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        s1 = self.skip1(s1)\n",
    "        x = self.down1(x)\n",
    "\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        s2 = x = F.leaky_relu(self.bn4(self.conv4(x)))\n",
    "        s2 = self.skip2(s2)\n",
    "        x = self.down2(x)\n",
    "\n",
    "        x = F.leaky_relu(self.bn5(self.conv5(x)))\n",
    "        s3 = x = F.leaky_relu(self.bn6(self.conv6(x)))\n",
    "        s3 = self.skip3(s3)\n",
    "        x = self.down3(x)\n",
    "\n",
    "        s4 = x = F.leaky_relu(self.bn7(self.conv7(x)))\n",
    "        s4 = self.skip4(s4)\n",
    "        x = F.leaky_relu(self.bn8(self.conv8(s4)))\n",
    "\n",
    "        x = self.up1(x)\n",
    "        x = F.leaky_relu(self.bn9(self.conv9(torch.cat((x, s3), 1))))\n",
    "        x = F.leaky_relu(self.bn10(self.conv10(x)))\n",
    "\n",
    "        x = self.up2(x)\n",
    "        x = F.leaky_relu(self.bn11(self.conv11(torch.cat((x, s2), 1))))\n",
    "        x = F.leaky_relu(self.bn12(self.conv12(x)))\n",
    "\n",
    "        x = self.up3(x)\n",
    "        x = torch.cat((x, s1), 1)\n",
    "        x = F.leaky_relu(self.bn13(self.conv13(x)))\n",
    "        x = F.leaky_relu(self.conv14(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "djgnet = AsymUNet(1)\n",
    "dd = torch.randn(2,1,512,128)\n",
    "dd = dd.cuda()\n",
    "djgnet = djgnet.to('cuda')\n",
    "yy = djgnet(dd)\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorwatch as tw\n",
    "tw.draw_model(djgnet, [2, 1, 512, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
