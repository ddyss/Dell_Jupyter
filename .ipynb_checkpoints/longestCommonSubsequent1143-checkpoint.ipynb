{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 572, 572])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from numpy.linalg import svd\n",
    "from numpy.random import normal\n",
    "from math import sqrt\n",
    "dd=torch.randn(1,1,572,572) \n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,colordim =1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(colordim, 64, 3)  # input of (n,n,1), output of (n-2,n-2,64)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        self.conv5_1 = nn.Conv2d(512, 1024, 3)\n",
    "        self.conv5_2 = nn.Conv2d(1024, 1024, 3)\n",
    "        self.upconv5 = nn.Conv2d(1024, 512, 1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.bn5_out = nn.BatchNorm2d(1024)\n",
    "        self.conv6_1 = nn.Conv2d(1024, 512, 3)\n",
    "        self.conv6_2 = nn.Conv2d(512, 512, 3)\n",
    "        self.upconv6 = nn.Conv2d(512, 256, 1)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.bn6_out = nn.BatchNorm2d(512)\n",
    "        self.conv7_1 = nn.Conv2d(512, 256, 3)\n",
    "        self.conv7_2 = nn.Conv2d(256, 256, 3)\n",
    "        self.upconv7 = nn.Conv2d(256, 128, 1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.bn7_out = nn.BatchNorm2d(256)\n",
    "        self.conv8_1 = nn.Conv2d(256, 128, 3)\n",
    "        self.conv8_2 = nn.Conv2d(128, 128, 3)\n",
    "        self.upconv8 = nn.Conv2d(128, 64, 1)\n",
    "        self.bn8 = nn.BatchNorm2d(64)\n",
    "        self.bn8_out = nn.BatchNorm2d(128)\n",
    "        self.conv9_1 = nn.Conv2d(128, 64, 3)\n",
    "        self.conv9_2 = nn.Conv2d(64, 64, 3)\n",
    "        self.conv9_3 = nn.Conv2d(64, colordim, 1)\n",
    "        self.bn9 = nn.BatchNorm2d(colordim)\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, return_indices=False, ceil_mode=False)\n",
    "        self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x1 = F.relu(self.bn1(self.conv1_2(F.relu(self.conv1_1(x1)))))\n",
    "        # print('x1 size: %d'%(x1.size(2)))\n",
    "        x2 = F.relu(self.bn2(self.conv2_2(F.relu(self.conv2_1(self.maxpool(x1))))))\n",
    "        # print('x2 size: %d'%(x2.size(2)))\n",
    "        x3 = F.relu(self.bn3(self.conv3_2(F.relu(self.conv3_1(self.maxpool(x2))))))\n",
    "        # print('x3 size: %d'%(x3.size(2)))\n",
    "        x4 = F.relu(self.bn4(self.conv4_2(F.relu(self.conv4_1(self.maxpool(x3))))))\n",
    "        # print('x4 size: %d'%(x4.size(2)))\n",
    "        xup = F.relu(self.conv5_2(F.relu(self.conv5_1(self.maxpool(x4)))))  # x5\n",
    "        # print('x5 size: %d'%(xup.size(2)))\n",
    "\n",
    "        xup = self.bn5(self.upconv5(self.upsample(xup)))  # x6in\n",
    "        cropidx = (x4.size(2) - xup.size(2)) // 2          #// 表示地板除，将除后的结果向下取整；均为int，结果为int，有一个float，结果为float\n",
    "        x4 = x4[:, :, cropidx:cropidx + xup.size(2), cropidx:cropidx + xup.size(2)]\n",
    "        # print('crop1 size: %d, x9 size: %d'%(x4crop.size(2),xup.size(2)))\n",
    "        xup = self.bn5_out(torch.cat((x4, xup), 1))  # x6 cat x4\n",
    "        xup = F.relu(self.conv6_2(F.relu(self.conv6_1(xup))))  # x6out\n",
    "\n",
    "        xup = self.bn6(self.upconv6(self.upsample(xup)))  # x7in\n",
    "        cropidx = (x3.size(2) - xup.size(2)) // 2\n",
    "        x3 = x3[:, :, cropidx:cropidx + xup.size(2), cropidx:cropidx + xup.size(2)]\n",
    "        # print('crop1 size: %d, x9 size: %d'%(x3crop.size(2),xup.size(2)))\n",
    "        xup = self.bn6_out(torch.cat((x3, xup), 1) ) # x7 cat x3\n",
    "        xup = F.relu(self.conv7_2(F.relu(self.conv7_1(xup))))  # x7out\n",
    "\n",
    "        xup = self.bn7(self.upconv7(self.upsample(xup)) ) # x8in\n",
    "        cropidx = (x2.size(2) - xup.size(2)) // 2\n",
    "        x2 = x2[:, :, cropidx:cropidx + xup.size(2), cropidx:cropidx + xup.size(2)]\n",
    "        # print('crop1 size: %d, x9 size: %d'%(x2crop.size(2),xup.size(2)))\n",
    "        xup = self.bn7_out(torch.cat((x2, xup), 1))  # x8 cat x2\n",
    "        xup = F.relu(self.conv8_2(F.relu(self.conv8_1(xup))))  # x8out\n",
    "\n",
    "        xup = self.bn8(self.upconv8(self.upsample(xup)) ) # x9in\n",
    "        cropidx = (x1.size(2) - xup.size(2)) // 2\n",
    "        x1 = x1[:, :, cropidx:cropidx + xup.size(2), cropidx:cropidx + xup.size(2)]\n",
    "        # print('crop1 size: %d, x9 size: %d'%(x1crop.size(2),xup.size(2)))\n",
    "        xup = self.bn8_out(torch.cat((x1, xup), 1))  # x9 cat x1\n",
    "        xup = F.relu(self.conv9_3(F.relu(self.conv9_2(F.relu(self.conv9_1(xup))))))  # x9out\n",
    "\n",
    "        return F.softsign(self.bn9(xup))\n",
    "\n",
    "\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "unet = UNet()\n",
    "#UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\djg\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0a215d1add90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\djg\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-f11a44d554dd>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x1)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;31m# print('crop1 size: %d, x9 size: %d'%(x1crop.size(2),xup.size(2)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mxup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn8_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# x9 cat x1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mxup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv9_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv9_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv9_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# x9out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftsign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn9\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\djg\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\djg\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 320\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "yy=unet(dd)\n",
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
