{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2560, 128])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "dd=torch.randn(1,1,2560,128) \n",
    "dd.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DjgNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DjgNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)      \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1) \n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 1, 1) \n",
    "        \n",
    "        self.conv9 = nn.Conv2d(256, 256, [20,3], [20,1], 1)\n",
    "        self.conv93 = nn.Conv2d(128, 128, [20,3], [20,1], 1)\n",
    "        self.conv92 = nn.Conv2d(64, 64, [20,3], [20,1], 1)\n",
    "        self.conv91 = nn.Conv2d(32, 32, [20,3], [20,1], 1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 128, 3, 1, 1)  \n",
    "        \n",
    "        self.conv63 = nn.ConvTranspose2d(128, 128, 4, 2, 1)\n",
    "        self.conv62 = nn.ConvTranspose2d(64, 64, 4, 2, 1)\n",
    "        self.conv61 = nn.ConvTranspose2d(32, 32, 4, 2, 1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(128, 64, 3, 1, 1)        \n",
    "        self.conv71 = nn.Conv2d(64, 32, 3, 1, 1)\n",
    "        self.conv72 = nn.Conv2d(32, 1, 3, 1, 1)\n",
    "        \n",
    "        self.conv8 = nn.ConvTranspose2d(32, 1, 4, 2, 1)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "#         self.pool2 = nn.MaxPool2d(2,return_indices=True)\n",
    "#         self.pool4 = nn.MaxUnpool2d(2)    #加了unpool 报forward 缺少1个indices的错\n",
    "#         layer4=nn.Sequential()\n",
    "#         layer4.add_module('fc1',nn.Linear(4096,512))\n",
    "#         layer4.add_module('fc_relu1',nn.ReLU(True))\n",
    "#         layer4.add_module('fc2',nn.Linear(512,64))\n",
    "#         layer4.add_module('fc_relu2',nn.ReLU(True))\n",
    "#         layer4.add_module('fc3',nn.Linear(64,10))\n",
    "#         self.layer4 = layer4\n",
    "\n",
    "#         self.fc1 = nn.Linear(4096,512)\n",
    "#         self.fc2 = nn.Linear(512,1024)\n",
    "        self.bn1 = nn.BatchNorm2d(1)\n",
    "        self.bn2 = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.bn4 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.bn5 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)      \n",
    "        x = self.bn2(x)\n",
    "        x1r = self.relu(x)\n",
    "        x = self.pool1(x1r)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn3(x)\n",
    "        x2r = self.relu(x)\n",
    "        x = self.pool1(x2r) \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn4(x)\n",
    "        x3r = self.relu(x)\n",
    "        x = self.pool1(x3r)        \n",
    "        x = self.conv4(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)        \n",
    "        x = self.conv9(x)          \n",
    "        x = self.conv5(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu(x)        #1,128,16,16\n",
    "        \n",
    "        xup3 = self.conv63(x)    \n",
    "        xadd1 = self.conv93(x3r)+xup3   #1,128,32,32  简单的相加不会改变tensor的形状  cat则是连接，会改变\n",
    "        x = self.conv7(xadd1)        \n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)     #1,64,32,32\n",
    "        \n",
    "        xup2 = self.conv62(x)        \n",
    "        xadd2 = self.conv92(x2r)+xup2   #1,64,64,64\n",
    "        x = self.conv71(xadd2)        \n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        xup1 = self.conv61(x)        \n",
    "        xadd1 = self.conv91(x1r)+xup1   #\n",
    "        x = self.conv72(xadd1)        \n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)        \n",
    "\n",
    "        return x\n",
    "\n",
    "djgnet=DjgNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "1\n",
      "torch.Size([1, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "yy=djgnet(dd)\n",
    "print(type(yy))\n",
    "print(len(yy))\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
