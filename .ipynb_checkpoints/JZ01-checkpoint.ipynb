{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io\n",
    "import torch.nn.functional as F\n",
    "# dd=torch.randn(1,1,512,128) \n",
    "# dd.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 512)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd=scipy.io.loadmat('F:/train/end to end 4560noiseball/several subset from 120.38below/e0r1_70.mat')['sensor_data']\n",
    "dd.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa=dd.T\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_data = torch.from_numpy(aa)\n",
    "torch_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 128])\n",
      "tensor([[[[ 5.3794e-04,  7.5845e-04, -4.2990e-04,  ...,  5.7053e-04,\n",
      "            1.9682e-03,  1.5374e-03],\n",
      "          [ 7.2268e-04, -1.0443e-03,  1.3045e-03,  ...,  1.2184e-03,\n",
      "            2.2506e-05,  1.1234e-03],\n",
      "          [-1.6775e-03,  5.1859e-04,  2.5060e-03,  ..., -1.5857e-03,\n",
      "            2.8463e-03,  2.2837e-03],\n",
      "          ...,\n",
      "          [-7.5939e-04, -7.2097e-04, -1.8363e-03,  ...,  1.0610e-04,\n",
      "           -3.2411e-04, -1.8843e-03],\n",
      "          [-2.0852e-04, -1.5447e-03, -3.1608e-05,  ..., -4.4720e-04,\n",
      "            3.6227e-04, -1.3460e-03],\n",
      "          [ 6.8911e-04,  1.1804e-03, -1.3937e-03,  ...,  3.5927e-04,\n",
      "           -3.0642e-04,  5.1943e-04]]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "input_data=torch_data.reshape(1,1,512,128)\n",
    "print(input_data.size())\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 128])\n",
      "tensor([[[[ 5.3794e-04,  7.5845e-04, -4.2990e-04,  ...,  5.7053e-04,\n",
      "            1.9682e-03,  1.5374e-03],\n",
      "          [ 7.2268e-04, -1.0443e-03,  1.3045e-03,  ...,  1.2184e-03,\n",
      "            2.2506e-05,  1.1234e-03],\n",
      "          [-1.6775e-03,  5.1859e-04,  2.5060e-03,  ..., -1.5857e-03,\n",
      "            2.8463e-03,  2.2837e-03],\n",
      "          ...,\n",
      "          [-7.5939e-04, -7.2097e-04, -1.8363e-03,  ...,  1.0610e-04,\n",
      "           -3.2411e-04, -1.8843e-03],\n",
      "          [-2.0852e-04, -1.5447e-03, -3.1608e-05,  ..., -4.4720e-04,\n",
      "            3.6227e-04, -1.3460e-03],\n",
      "          [ 6.8911e-04,  1.1804e-03, -1.3937e-03,  ...,  3.5927e-04,\n",
      "           -3.0642e-04,  5.1943e-04]]]])\n"
     ]
    }
   ],
   "source": [
    "input_data=input_data.float()   #######################在进入训练前.float\n",
    "print(input_data.size())\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#归一化\n",
    "# input_datamin, input_datamax = input_data.min(), input_data.max() # 求最大最小值\n",
    "# bb = (input_data-input_datamin)/(input_datamax-input_datamin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb=bb.float()   #######################在进入训练前.float\n",
    "# print(bb.size())\n",
    "# print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DjgNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DjgNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, 3, 1, 1)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)      \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1) \n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 1, 1) \n",
    "        \n",
    "        self.conv9 = nn.Conv2d(256, 256, [4,3], [4,1], 1)\n",
    "        self.conv93 = nn.Conv2d(128, 128, [4,3], [4,1], 1)\n",
    "        self.conv92 = nn.Conv2d(64, 64, [4,3], [4,1], 1)\n",
    "        self.conv91 = nn.Conv2d(32, 32, [4,3], [4,1], 1)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 128, 3, 1, 1)  \n",
    "        \n",
    "        self.conv63 = nn.ConvTranspose2d(128, 128, 4, 2, 1)\n",
    "        self.conv62 = nn.ConvTranspose2d(64, 64, 4, 2, 1)\n",
    "        self.conv61 = nn.ConvTranspose2d(32, 32, 4, 2, 1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(128, 64, 3, 1, 1)        \n",
    "        self.conv71 = nn.Conv2d(64, 32, 3, 1, 1)\n",
    "        self.conv72 = nn.Conv2d(32, 1, 3, 1, 1)\n",
    "        \n",
    "        self.conv8 = nn.ConvTranspose2d(32, 1, 4, 2, 1)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "#         self.pool2 = nn.MaxPool2d(2,return_indices=True)\n",
    "#         self.pool4 = nn.MaxUnpool2d(2)    #加了unpool 报forward 缺少1个indices的错\n",
    "#         layer4=nn.Sequential()\n",
    "#         layer4.add_module('fc1',nn.Linear(4096,512))\n",
    "#         layer4.add_module('fc_relu1',nn.ReLU(True))\n",
    "#         layer4.add_module('fc2',nn.Linear(512,64))\n",
    "#         layer4.add_module('fc_relu2',nn.ReLU(True))\n",
    "#         layer4.add_module('fc3',nn.Linear(64,10))\n",
    "#         self.layer4 = layer4\n",
    "\n",
    "#         self.fc1 = nn.Linear(4096,512)\n",
    "#         self.fc2 = nn.Linear(512,1024)\n",
    "        self.bn1 = nn.BatchNorm2d(1)\n",
    "        self.bn2 = nn.BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.bn4 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.bn5 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)      \n",
    "#         x = self.bn2(x)\n",
    "#         x1r = self.relu(x)\n",
    "#         x = self.pool1(x1r)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn3(x)\n",
    "#         x2r = self.relu(x)\n",
    "#         x = self.pool1(x2r) \n",
    "#         x = self.conv3(x)\n",
    "#         x = self.bn4(x)\n",
    "#         x3r = self.relu(x)\n",
    "#         x = self.pool1(x3r)        \n",
    "#         x = self.conv4(x)\n",
    "#         x = self.bn5(x)\n",
    "#         x = self.relu(x)        \n",
    "#         x = self.conv9(x)          \n",
    "#         x = self.conv5(x)\n",
    "#         x = self.bn4(x)\n",
    "#         x = self.relu(x)        #1,128,16,16\n",
    "        \n",
    "#         xup3 = self.conv63(x)    \n",
    "#         xadd1 = self.conv93(x3r)+xup3   #1,128,32,32  简单的相加不会改变tensor的形状  cat则是连接，会改变\n",
    "#         x = self.conv7(xadd1)        \n",
    "#         x = self.bn3(x)\n",
    "#         x = self.relu(x)     #1,64,32,32\n",
    "        \n",
    "#         xup2 = self.conv62(x)        \n",
    "#         xadd2 = self.conv92(x2r)+xup2   #1,64,64,64\n",
    "#         x = self.conv71(xadd2)        \n",
    "#         x = self.bn2(x)\n",
    "#         x = self.relu(x)\n",
    "        \n",
    "#         xup1 = self.conv61(x)        \n",
    "#         xadd1 = self.conv91(x1r)+xup1   #\n",
    "#         x = self.conv72(xadd1)        \n",
    "#         x = self.bn1(x)\n",
    "#         x = self.relu(x)        \n",
    "\n",
    "        return x\n",
    "\n",
    "djgnet=DjgNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "1\n",
      "torch.Size([1, 1, 512, 128])\n"
     ]
    }
   ],
   "source": [
    "# yy=djgnet(bb)\n",
    "yy=djgnet(input_data)\n",
    "print(type(yy))\n",
    "print(len(yy))\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "aaa=yy.data.numpy()\n",
    "aaa=aaa.reshape(512,128)\n",
    "scipy.io.savemat('F:/colorbar/CNN-end2end/byconv1.mat',{'out': aaa})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 128)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
