{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd=torch.randn(10,10,128) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_1(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_rate=0.5):\n",
    "        super(CNN_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.conv1_1 = nn.Conv1d(1, 8, kernel_size=8, stride=2, padding=3)#输入3840，输出1920\n",
    "        self.conv1_2 = nn.Conv1d(1, 8, kernel_size=16, stride=2, padding=7)#输入3840，输出1920\n",
    "        self.conv1_3 = nn.Conv1d(1, 8, kernel_size=32, stride=2, padding=15)#输入3840，输出1920\n",
    "        self.conv1_4 = nn.Conv1d(1, 8, kernel_size=64, stride=2, padding=31)#输入3840，输出1920\n",
    "\n",
    "        self.norm1 = nn.BatchNorm1d(32) # 1920   所以4*8=32个通道\n",
    "        self.pool1 = nn.MaxPool1d(6, stride=4, padding=1, return_indices=True) # 480  所以1920/4=480\n",
    "\n",
    "        self.conv2_1 = nn.Conv1d(32, 16, kernel_size=3, stride=1, padding=1) #尺寸不变\n",
    "        self.conv2_2 = nn.Conv1d(32, 16, kernel_size=5, stride=1, padding=2) #尺寸不变\n",
    "\n",
    "        self.norm2 = nn.BatchNorm1d(32)   #所以又16*2=32通道\n",
    "        self.pool2 = nn.MaxPool1d(3, stride=2, padding=1, return_indices=True) # 240\n",
    "\n",
    "\n",
    "        self.conv3_1 = nn.Conv1d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_2 = nn.Conv1d(32, 16, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.norm3 = nn.BatchNorm1d(32)\n",
    "        self.pool3 = nn.MaxPool1d(3, stride=2, padding=1, return_indices=True) # 120 x 32  大小120，通道32\n",
    "\n",
    "        self.fc = nn.Linear(61*32, hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # batch x 1 x raw_feature\n",
    "\n",
    "        encoded = torch.cat([self.conv1_1(x),self.conv1_2(x),self.conv1_3(x),self.conv1_4(x)],1)\n",
    "        encoded = self.relu(self.norm1(encoded))\n",
    "        encoded, indices1 = self.pool1(encoded)\n",
    "\n",
    "        encoded = torch.cat([self.conv2_1(encoded),self.conv2_2(encoded)],1)\n",
    "        encoded = self.relu(self.norm2(encoded))\n",
    "        encoded, indices2 = self.pool2(encoded)\n",
    "\n",
    "        encoded = torch.cat([self.conv3_1(encoded),self.conv3_2(encoded)],1)\n",
    "        encoded = self.relu(self.norm3(encoded))\n",
    "        encoded, indices3 = self.pool3(encoded)\n",
    "\n",
    "        encoded = self.relu(self.fc(encoded.view(encoded.size(0),-1))) # batch x hidden_size\n",
    "        return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_0(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout_rate=0.5):\n",
    "        super(CNN_0, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(1, 8, kernel_size=(1,8), stride=(1,2), padding=(0,3))\n",
    "        self.conv1_2 = nn.Conv2d(1, 8, kernel_size=(1,16), stride=(1,2), padding=(0,7))\n",
    "        self.conv1_3 = nn.Conv2d(1, 8, kernel_size=(1,32), stride=(1,2), padding=(0,15))\n",
    "        self.conv1_4 = nn.Conv2d(1, 8, kernel_size=(1,64), stride=(1,2), padding=(0,31))\n",
    "\n",
    "        self.norm1 = nn.BatchNorm2d(32) #\n",
    "        self.pool1 = nn.AvgPool2d((1,6), stride=(1,4), padding=(0,1)) #\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(32, 16, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.norm2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.AvgPool2d((1,3), stride=(1,2), padding=(0,1)) #\n",
    "\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(32, 16, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.norm3 = nn.BatchNorm2d(32)\n",
    "        self.pool3 = nn.AvgPool2d((5,3), stride=(5,2), padding=(0,1)) #\n",
    "\n",
    "        self.fc = nn.Linear(61*32, hidden_size) #\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # shape: batch x 1 x channel5 x raw_feature1950\n",
    "\n",
    "        encoded = torch.cat([self.conv1_1(x),self.conv1_2(x),self.conv1_3(x),self.conv1_4(x)],1)\n",
    "        encoded = self.relu(self.norm1(encoded))\n",
    "        encoded = self.pool1(encoded)\n",
    "\n",
    "        encoded = torch.cat([self.conv2_1(encoded),self.conv2_2(encoded)],1)\n",
    "        encoded = self.relu(self.norm2(encoded))\n",
    "        encoded = self.pool2(encoded)\n",
    "\n",
    "        encoded = torch.cat([self.conv3_1(encoded),self.conv3_2(encoded)],1)\n",
    "        encoded = self.relu(self.norm3(encoded))\n",
    "        encoded = self.pool3(encoded)\n",
    "\n",
    "        encoded = self.relu(self.fc(encoded.view(encoded.size(0),-1))) # batch x hidden_size\n",
    "        return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_v(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention_v, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.rg = nn.Linear(hidden_size,1)\n",
    "        self.rc = nn.Linear(hidden_size,1)\n",
    "        self.attention_layer = nn.Linear(self.hidden_size,1)\n",
    "\n",
    "    def forward(self, h_c, h_g):\n",
    "        # shape h_c: batch x channel x hidden_size\n",
    "        # shape h_g: batch x hidden_size\n",
    "        batch_size = h_c.size(0)\n",
    "        num_channel = h_c.size(1)\n",
    "\n",
    "        scores = to_var(torch.zeros((batch_size, num_channel))) # batch x channel\n",
    "\n",
    "        for i in range(num_channel):\n",
    "            scores[:,i] = self.energy(h_g,h_c[:,i,:])\n",
    "        scores = F.softmax(scores)\n",
    "        scores = scores.view(scores.size(0),scores.size(1),-1) # batch x channel x 1\n",
    "        scores = scores.expand(scores.size(0),scores.size(1),self.hidden_size) # batch x channel x hidden_size\n",
    "\n",
    "        context = h_c * scores\n",
    "        context_vector = context.sum(1) # batch x hidden_size\n",
    "\n",
    "        out = torch.cat([context_vector,h_g],1) # batch x 2*hidden_size\n",
    "        return out, scores\n",
    "\n",
    "    def energy(self, hidden_i, pre_hidden_i): # batch x hidden_size\n",
    "\n",
    "        rate = self.sigmoid(self.rg(hidden_i) + self.rc(pre_hidden_i))\n",
    "\n",
    "        rate = rate.view(rate.size(0),-1)\n",
    "        rate = rate.expand(rate.size(0),self.hidden_size)\n",
    "        out_temp = (1-rate) * hidden_i + rate * pre_hidden_i\n",
    "\n",
    "        energies = self.attention_layer(out_temp)\n",
    "        energies= energies.view(energies.size(0)) # new added due to some reasons\n",
    "\n",
    "        return energies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, dropout=self.dropout,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "    def forward(self, x, hidden=None):\n",
    "        # shape: batch x seq x input_size\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_t(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention_t, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.rg = nn.Linear(hidden_size,1)\n",
    "        self.rc = nn.Linear(hidden_size,1)\n",
    "        self.attention_layer = nn.Linear(self.hidden_size,1)\n",
    "\n",
    "    def forward(self, h):\n",
    "        # shape: batch x seq x hidden_size\n",
    "        batch_size = h.size(0)\n",
    "        seq_size = h.size(1)\n",
    "\n",
    "        context_vector = to_var(torch.zeros((batch_size, seq_size, self.hidden_size)))\n",
    "\n",
    "        for i in range(h.size(1)):\n",
    "            h_i = h[:,i,:] # current hidden state: batch x hidden_size\n",
    "            if i == 0:\n",
    "                scores = to_var(torch.zeros((batch_size, 1)))\n",
    "                pre_h_i = h[:, i, :] * 0.0 # batch x hidden_size\n",
    "            else:\n",
    "                scores = to_var(torch.zeros((batch_size, i)))\n",
    "                pre_h_i = h[:, :i, :] # previous hidden states: batch x sub_seq_size x hidden_size\n",
    "                for j in range(pre_h_i.size(1)):\n",
    "                    scores[:,j] = self.energy(h_i, pre_h_i[:,j,:]) # batch x 1\n",
    "\n",
    "            scores = F.softmax(scores) # batch x sub_seq_size\n",
    "\n",
    "            scores = scores.view(scores.size(0),scores.size(1),-1) # batch x sub_seq_size x 1\n",
    "            scores = scores.expand(scores.size(0),scores.size(1),self.hidden_size) # batch x sub_seq_size x hidden_size\n",
    "\n",
    "            context = pre_h_i * scores # batch x sub_seq_size x hidden_size\n",
    "            context_vector[:,i,:] = context.sum(1) # batch x hidden_size\n",
    "\n",
    "        out = torch.cat([context_vector,h],2) # batch x seq x hidden_size\n",
    "        return out,scores\n",
    "\n",
    "    def energy(self, hidden_i, pre_hidden_i): # batch x hidden_size\n",
    "\n",
    "        rate = self.sigmoid(self.rg(hidden_i) + self.rc(pre_hidden_i))\n",
    "\n",
    "        rate = rate.view(rate.size(0),-1)\n",
    "        rate = rate.expand(rate.size(0),self.hidden_size)\n",
    "        out_temp = (1-rate) * hidden_i + rate * pre_hidden_i\n",
    "\n",
    "        energies = self.attention_layer(out_temp)\n",
    "        energies= energies.view(energies.size(0)) # new added due to some reasons\n",
    "\n",
    "        return energies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "djgnet=Net(input_size=3840, hidden1_size=128, hidden2_size=128, num_layers=2, num_classes=5, num_channel=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\djg\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected type torch.FloatTensor but got torch.cuda.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-875313e9c8eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdjgnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\djg\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b1a7380c725f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, h)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# batch x sub_seq_size x hidden_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_h_i\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;31m# batch x sub_seq_size x hidden_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mcontext_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# batch x hidden_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected type torch.FloatTensor but got torch.cuda.FloatTensor"
     ]
    }
   ],
   "source": [
    "yy=djgnet(dd)\n",
    "print(type(yy))\n",
    "print(len(yy))\n",
    "print(yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
